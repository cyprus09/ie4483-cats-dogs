{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Pre-trained VGG16 for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to implement and train a pretrained VGG16 model using PyTorch for binary image classification (Dogs vs Cats). We'll break down the implementation into several key sections,\n",
    "1. Setting up the environment and importing dependencies\n",
    "2. Data preparation and loading\n",
    "3. Model architecture implementation\n",
    "4. Training utilities and visualization functions\n",
    "5. Training loop and model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 256\n",
    "IMG_SIZE = 224\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Augmentation and Transforms\n",
    "We'll set up data augmentation for training and basic transforms for validation. Data augmentation helps prevent overfitting and improves model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transforms with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomAffine(0, translate=(0.14, 0.14)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4863, 0.4532, 0.4155], std=[0.2621, 0.2557, 0.2582]) #eda based on train dataset\n",
    "])\n",
    "# Validation transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4863, 0.4532, 0.4155], std=[0.2621, 0.2557, 0.2582]) #eda\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dataset Loading\n",
    "Now we'll load our datasets using PyTorch's ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root='datasets/datasets/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root='datasets/datasets/val',\n",
    "    transform=val_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "We'll implement Pretrained VGG16 as base model and remove top original classifier layer and add new classifier with batch normalization and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16Model(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        # Load pretrained VGG16\n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        \n",
    "        # Freeze VGG16 layers\n",
    "        for param in self.vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Remove original classifier\n",
    "        self.features = self.vgg16.features\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(512 * 7 * 7),\n",
    "            nn.Linear(512 * 7 * 7, 256),\n",
    "            nn.Softplus(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, 256),\n",
    "            nn.Softplus(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\"\n",
    "model = VGG16Model().to(device)\n",
    "# Print model summary,\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Utilities\n",
    "### 4.1 Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs, title=''):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    \n",
    "    # Loss plot\n",
    "    ax[0].plot(train_losses, label='Training Loss')\n",
    "    ax[0].plot(val_losses, label='Validation Loss')\n",
    "    ax[0].legend(loc='upper right')\n",
    "    ax[0].set_title(title + ' Loss')\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax[1].plot(train_accs, label='Training Accuracy')\n",
    "    ax[1].plot(val_accs, label='Validation Accuracy')\n",
    "    ax[1].legend(loc='lower right')\n",
    "    ax[1].set_title(title + ' Accuracy')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    since = time.time()\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        \n",
    "        # Update best accuracy\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            \n",
    "        # Save best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "            }, 'ptVgg16.pth')\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc)) \n",
    "      \n",
    "    return train_losses, val_losses, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function (criterion)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer with initial learning rate\n",
    "initial_lr = 0.001\n",
    "optimizer = optim.SGD(params=params_to_update, lr=0.initial_lr, momentum=0.9) # try SGD\n",
    "# optimizer = optim.Adam(model.parameters(), lr=initial_lr, weight_decay=1e-4)  # Added weight decay for regularization\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the history\n",
    "train_losses, val_losses, train_accs, val_accs, best_acc = history\n",
    "\n",
    "# Plot the results\n",
    "plot_metrics(train_losses, val_losses, train_accs, val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Test dataset and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs:\n",
    "1. Model loading and inference on test dataset\n",
    "2. CSV generation for predictions\n",
    "3. Visualization of results\n",
    "4. Feature map extraction and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model loading and inference on test dataset\n",
    "### 1.1 Test dataset transforms and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4863, 0.4532, 0.4155], std=[0.2621, 0.2557, 0.2582])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset directly from folder\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=\"datasets/test\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Model loading and inference on processed test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load('ptVgg16.pth')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths\n",
    "file_paths = [os.path.basename(x[0]) for x in test_dataset.imgs]\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images = batch[0].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export CSV for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with predictions\n",
    "df_predictions = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predictions) + 1),\n",
    "    'Label': predictions,\n",
    "    'Prediction': [class_names[p] for p in predictions],\n",
    "    'Filename': file_paths\n",
    "})\n",
    "\n",
    "# Save predictions to CSV\n",
    "df_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizations of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualise predictions in plot to check which image is classified incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 100 predictions\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(100):\n",
    "    ax = plt.subplot(10, 10, i + 1)\n",
    "    \n",
    "    # Get and display image\n",
    "    image, _ = test_dataset[i]\n",
    "    img = image.permute(1, 2, 0)\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "    img = img.numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[predictions[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 2nd 100 predictions\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(100,200):\n",
    "    ax = plt.subplot(10, 10, i + 1)\n",
    "    \n",
    "    # Get and display image\n",
    "    image, _ = test_dataset[i]\n",
    "    img = image.permute(1, 2, 0)\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "    img = img.numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[predictions[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 2nd 100 predictions\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(200, 300):\n",
    "    ax = plt.subplot(10, 10, i + 1)\n",
    "    \n",
    "    # Get and display image\n",
    "    image, _ = test_dataset[i]\n",
    "    img = image.permute(1, 2, 0)\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "    img = img.numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[predictions[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 3rd 100 predictions\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(300, 400):\n",
    "    ax = plt.subplot(10, 10, i + 1)\n",
    "    \n",
    "    # Get and display image\n",
    "    image, _ = test_dataset[i]\n",
    "    img = image.permute(1, 2, 0)\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "    img = img.numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[predictions[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 3rd 100 predictions\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(400, 500):\n",
    "    ax = plt.subplot(10, 10, i + 1)\n",
    "    \n",
    "    # Get and display image\n",
    "    image, _ = test_dataset[i]\n",
    "    img = image.permute(1, 2, 0)\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "    img = img.numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(class_names[predictions[i]])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Map Extraction and Visualization for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.features = {}\n",
    "        \n",
    "        # Register hooks for VGG features\n",
    "        self.conv_layers = [\n",
    "            'features.2',  # After first conv block\n",
    "            'features.7',  # After second conv block\n",
    "            'features.14', # Middle of network\n",
    "            'features.21', # Later conv block\n",
    "            'features.28'  # Last conv layer\n",
    "        ]\n",
    "        \n",
    "        # Register hooks for classifier layers\n",
    "        self.classifier_layers = [\n",
    "            'classifier.2',  # First Linear + Softplus\n",
    "            'classifier.6',  # Second Linear + Softplus\n",
    "            'classifier.10', # Third Linear + Softplus\n",
    "            'classifier.14'  # Fourth Linear + Softplus\n",
    "        ]\n",
    "        \n",
    "        # Register hooks for all target layers\n",
    "        for name, layer in model.named_modules():\n",
    "            if name in self.conv_layers or name in self.classifier_layers:\n",
    "                layer.register_forward_hook(self.save_feature_maps(name))\n",
    "    \n",
    "    def save_feature_maps(self, name):\n",
    "        def hook(module, input, output):\n",
    "            self.features[name] = output.detach()\n",
    "        return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(feature_maps, layer_name, num_features=16):\n",
    "    # Handle both convolutional and linear layer outputs\n",
    "    if len(feature_maps.shape) == 4:  # Conv layer (B, C, H, W)\n",
    "        feature_maps = feature_maps[0]  # Get first batch\n",
    "        n_features = min(num_features, feature_maps.shape[0])\n",
    "        grid_size = int(np.ceil(np.sqrt(n_features)))\n",
    "        \n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.suptitle(f'Feature Maps for {layer_name}', fontsize=16)\n",
    "        \n",
    "        for idx in range(n_features):\n",
    "            plt.subplot(grid_size, grid_size, idx + 1)\n",
    "            plt.imshow(feature_maps[idx].cpu(), cmap='viridis')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Filter {idx}')\n",
    "            \n",
    "    else:  # Linear layer (B, N)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.suptitle(f'Activation Values for {layer_name}', fontsize=16)\n",
    "        plt.plot(feature_maps[0].cpu().numpy())\n",
    "        plt.xlabel('Neuron Index')\n",
    "        plt.ylabel('Activation Value')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare image\n",
    "image_path = 'datasets/test/500.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your custom model\n",
    "checkpoint = torch.load('ptVgg16.pth')\n",
    "model = VGG16Model()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature extractor\n",
    "feature_extractor = FeatureExtractor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction and features\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    features = feature_extractor.features\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    prediction = class_names[predicted.item()]\n",
    "    probabilities = output[0]  # Already softmax in model\n",
    "    \n",
    "print(f'Predicted class: {prediction}')\n",
    "print(f'Probabilities: Cat: {probabilities[0]:.3f}, Dog: {probabilities[1]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convolutional feature maps\n",
    "print(\"\\nConvolutional Layer Feature Maps:\")\n",
    "for layer_name in feature_extractor.conv_layers:\n",
    "    if layer_name in features:\n",
    "        print(f\"\\nVisualizing {layer_name}:\")\n",
    "        visualize_feature_maps(features[layer_name], layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize classifier layer activations\n",
    "print(\"\\nClassifier Layer Activations:\")\n",
    "for layer_name in feature_extractor.classifier_layers:\n",
    "    if layer_name in features:\n",
    "        print(f\"\\nVisualizing {layer_name}:\")\n",
    "        visualize_feature_maps(features[layer_name], layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics analysis\n",
    "print(\"\\nFeature Map Statistics:\")\n",
    "for layer_name, feature_map in features.items():\n",
    "    feature_map = feature_map[0].cpu()  # Get first image if batch\n",
    "    stats = {\n",
    "        'mean': feature_map.mean().item(),\n",
    "        'std': feature_map.std().item(),\n",
    "        'min': feature_map.min().item(),\n",
    "        'max': feature_map.max().item(),\n",
    "        'active_neurons': (feature_map > 0).float().mean().item() * 100  # % of active neurons\n",
    "    }\n",
    "    print(f\"\\n{layer_name}:\")\n",
    "    for stat_name, value in stats.items():\n",
    "        print(f\"{stat_name}: {value:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
